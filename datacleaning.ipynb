{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70520903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steam Game Similarity Project\n",
    "#COP3530\n",
    "\n",
    "#This file takes a csv file containing the raw information of games on steam, processes it, and outputs two files.\n",
    "\n",
    "#The first output is a Numpy file containing a 2D Numpy Array of the processed game data\n",
    "#The second output is a JSON file containing metadata in the following format:\n",
    "    #First line contains a list of column names for all the columns in output 1\n",
    "    #Second line onwards contains a dictionary for every game, mapping the unique AppID to various game metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Creates an input path for the raw data\n",
    "dir = \"resources\"\n",
    "subfolder = \"raw_data\"\n",
    "sub_path = os.path.join(dir, subfolder)\n",
    "raw_data_path = os.path.join(sub_path, \"games.csv\")\n",
    "\n",
    "#Reads raw data file (.csv) and creates a Panda dataframe from it\n",
    "df = pd.read_csv(raw_data_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces invalid NaN fields with blank strings\n",
    "df['Categories'] = df['Categories'].fillna('')\n",
    "df['Genres'] = df['Genres'].fillna('')\n",
    "df['Tags'] = df['Tags'].fillna('')\n",
    "df['Name'] = df['Name'].fillna('')\n",
    "\n",
    "#Creates a new dataframe for the metadata of each game\n",
    "df_metadata = df[[\"AppID\", \"Name\", \"Release date\", \"About the game\", \"Developers\", \"Categories\", \"Genres\", \"Tags\"]]\n",
    "\n",
    "#Setting the index to the AppID\n",
    "df.set_index(\"AppID\", inplace=True)\n",
    "\n",
    "#Drops columns that aren't needed for data processing\n",
    "df.drop(columns = [\"Name\", \"Release date\", \"Estimated owners\", \"Peak CCU\", \"Required age\", \"Price\", \"Discount\", \"DLC count\", \"About the game\", \"Supported languages\", \"Full audio languages\", \"Reviews\", \"Header image\", \"Website\", \"Support url\", \"Support email\", \"Windows\", \"Mac\", \"Linux\", \"Metacritic url\", \"User score\", \"Score rank\", \"Achievements\", \"Recommendations\", \"Notes\", \"Median playtime forever\", \"Median playtime two weeks\", \"Developers\", \"Publishers\", \"Screenshots\", \"Movies\"], inplace = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe54e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Separates data within columns for categories/genres/tags to be processed\n",
    "\n",
    "\n",
    "#Lists containing categories/genres/tags to be used\n",
    "categories_keep = [\n",
    "    \"co-op\", \"cross-platform multiplayer\", \"full controller support\",\n",
    "    \"mmo\", \"multi-player\", \"pvp\", \"single-player\", \"vr only\",\n",
    "    \"vr support\", \"vr supported\"\n",
    "]\n",
    "\n",
    "genres_keep = [\n",
    "    \"action\", \"adventure\", \"casual\", \"early access\", \"education\", \n",
    "    \"free to play\", \"gore\", \"indie\", \"massively multiplayer\",\n",
    "    \"nudity\", \"rpg\", \"racing\", \"sexual content\", \"simulation\", \n",
    "    \"sports\", \"strategy\", \"violent\"\n",
    "]\n",
    "\n",
    "tags_keep = [\n",
    "    \"arcade\", \"shooter\", \"action-adventure\", \"platformer\", \"horror\",\n",
    "    \"visual novel\", \"2d platformer\", \"sexual content\", \"point & click\",\n",
    "    \"fps\", \"rogue-like\", \"rogue-lite\", \"hidden object\", \"3d platformer\",\n",
    "    \"sandbox\", \"action roguelike\", \"survival\", \"side scroller\",\n",
    "    \"action rpg\", \"open world\", \"bullet hell\", \"interactive fiction\",\n",
    "    \"turn-based strategy\", \"shoot 'em up\", \"choose your own adventure\",\n",
    "    \"dating sim\", \"immersive sim\", \"walking simulator\", \"clicker\",\n",
    "    \"management\", \"turn-based tactics\", \"jrpg\", \"card game\", \"building\",\n",
    "    \"hack and slash\", \"top-down shooter\", \"dungeon crawler\",\n",
    "    \"survival horror\", \"precision platformer\", \"education\",\n",
    "    \"tower defense\", \"life sim\", \"board game\", \"idler\",\n",
    "    \"third-person shooter\", \"rts\", \"time management\", \"collectathon\",\n",
    "    \"arena shooter\", \"runner\", \"base building\", \"strategy rpg\",\n",
    "    \"real time tactics\", \"city builder\", \"stealth\", \"beat 'em up\",\n",
    "    \"wargame\", \"flight\", \"card battler\", \"2d fighter\", \"metroidvania\",\n",
    "    \"investigation\", \"party-based rpg\", \"rhythm\", \"tactical rpg\",\n",
    "    \"match 3\", \"souls-like\", \"twin stick shooter\", \"3d fighter\",\n",
    "    \"automobile sim\", \"word game\"\n",
    "]\n",
    "\n",
    "#Converts the lists of categories for all the games to column headers with binary values (1 if present for a game, 0 if not present) and stores it in a new dataframe\n",
    "col_data = df[\"Categories\"].str.get_dummies(sep=',')\n",
    "#Iterates through each column in new category dataframe and removes any columns that aren't named above\n",
    "for col in col_data.columns:\n",
    "    if col.lower() not in categories_keep:\n",
    "        col_data.drop(columns = col, inplace = True)\n",
    "#Concatonates the main dataframe with new, processed categories dataframe\n",
    "df = pd.concat([df, col_data], axis=1)\n",
    "\n",
    "#Repeat for genres/tags columns\n",
    "\n",
    "col_data = df[\"Genres\"].str.get_dummies(sep=',')\n",
    "for col in col_data.columns:\n",
    "    if col.lower() not in genres_keep:\n",
    "        col_data.drop(columns = col, inplace = True)\n",
    "df = pd.concat([df, col_data], axis=1)\n",
    "\n",
    "col_data = df[\"Tags\"].str.get_dummies(sep=',')\n",
    "for col in col_data.columns:\n",
    "    if col.lower() not in tags_keep:\n",
    "        col_data.drop(columns = col, inplace = True)\n",
    "df = pd.concat([df, col_data], axis=1)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e847dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Attempt to use TF-IDF to more methodically determine weights to be used in Cosine Similarity\n",
    "# Currently not implemented/finished\n",
    "\n",
    "'''#Custom tokenizer used for TF-IDF analysis\n",
    "def data_delimiter(raw_data):\n",
    "    #If data is a string, returns an array of individual tokens in string\n",
    "    if isinstance(raw_data, str):\n",
    "        return [token.strip() for token in raw_data.split(',')]\n",
    "    #Returns empty array if data is not a string\n",
    "    return []\n",
    "\n",
    "#Creates a vectorizer for the category column that tokenizes the data (also filters out undesired categories)\n",
    "category_vectorizer = TfidfVectorizer(tokenizer=data_delimiter, vocabulary=categories_keep, lowercase=True)\n",
    "#Applies a fit and transform to the vectorizer object and creates a matrix containing the TF-IDF values\n",
    "category_matrix = category_vectorizer.fit_transform(df['Categories'])\n",
    "#Converts the matrix to a pandas dataframe\n",
    "tfidf_category = pd.DataFrame(category_matrix.toarray(), columns=category_vectorizer.get_feature_names_out())\n",
    "\n",
    "#Repeat for genres/tags\n",
    "\n",
    "genre_vectorizer = TfidfVectorizer(tokenizer=data_delimiter, vocabulary=genres_keep, lowercase=True)\n",
    "genre_matrix = genre_vectorizer.fit_transform(df['Genres'])\n",
    "tfidf_genre = pd.DataFrame(genre_matrix.toarray(), columns=genre_vectorizer.get_feature_names_out())\n",
    "\n",
    "tag_vectorizer = TfidfVectorizer(tokenizer=data_delimiter, vocabulary=tags_keep, lowercase=True)\n",
    "tag_matrix = tag_vectorizer.fit_transform(df['Tags'])\n",
    "tfidf_tag = pd.DataFrame(tag_matrix.toarray(), columns=tag_vectorizer.get_feature_names_out())\n",
    "\n",
    "#Concatonates results for all three dataframes\n",
    "tfidf_df = pd.concat([tfidf_category, tfidf_genre, tfidf_tag], axis=1)\n",
    "\n",
    "tfidf_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Drops additional unecessary columns and creates new copy of dataframe\n",
    "df.drop(columns=[\"Categories\", \"Genres\", \"Tags\"], inplace=True)\n",
    "df_clean = df\n",
    "\n",
    "#Uses a standard scaler object to standardize the highly variable numeric columns\n",
    "SS_obj = StandardScaler()\n",
    "input_data = df_clean[[\"Metacritic score\", \"Positive\", \"Negative\", \"Average playtime forever\", \"Average playtime two weeks\"]]\n",
    "scaled_data = SS_obj.fit_transform(input_data)\n",
    "\n",
    "#Applies the scaled data to the cleaned dataframe\n",
    "df_clean[[\"Metacritic score\", \"Positive\", \"Negative\", \"Average playtime forever\", \"Average playtime two weeks\"]] = scaled_data\n",
    "df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an array to store weights for each attribute in cleaned dataframe\n",
    "'''\n",
    "weights = [0.7] * 5\n",
    "weights.extend([1.5] * 10)\n",
    "weights.extend([2] * 18)\n",
    "weights.extend([2.5] * 70)\n",
    "'''\n",
    "\n",
    "#Experimental weights\n",
    "weights_exp = [0.7, 0.7, 0.7, 0.7, 0.7, 1.780696682, 2.467798285, 1.473799925, 2.852225591, 1.509064207, 1.696370871, \n",
    "               1.0, 3.077217004, 5.237086206, 6.040871766, 1.233739558, 1.247938459, 1.216512239, \n",
    "               1.634166298, 2.612642298, 2.633431688, 1.885314883, 4.765946961, 1.077988234, \n",
    "               2.484565306, 7.0, 1.509640523, 2.257082312, 3.913769316, 1.466396768, 2.149983971, \n",
    "               1.488056209, 3.944654261, 3.298957458, 2.128393911, 3.69614556, 2.400646202, \n",
    "               2.350939516, 2.508930323, 1.916668871, 1.81180569, 2.938879925, 3.239304601, \n",
    "               3.070256505, 2.85174691, 2.342811843, 2.461797796, 3.405113191, 2.74922492, \n",
    "               2.529522368, 2.989363701, 2.756847798, 3.069564772, 2.860911204, 2.581476769, \n",
    "               1.743890385, 2.149285281, 3.01598798, 2.547709997, 2.337647706, 1.878547822, \n",
    "               3.11771541, 2.544452743, 2.514764789, 2.787154224, 2.607112866, 2.84650777, \n",
    "               2.327487588, 3.384523722, 3.135144076, 2.078889233, 3.221456513, 1.915685813, \n",
    "               2.192440358, 2.783327166, 2.81425535, 3.006565847, 3.366733231, 2.262013242, \n",
    "               2.29568155, 3.062006749, 2.250883505, 1.611278839, 2.438503058, 1.894056304, \n",
    "               2.29762677, 3.274630792, 2.702656321, 2.970291827, 2.053667383, 2.416897595, \n",
    "               3.125233467, 2.823284197, 2.892390211, 2.665554665, 2.828312328, 2.434364634, \n",
    "               2.513490651, 3.248416659, 2.139166388, 2.483845247, 3.120711776, 3.67204272]\n",
    "\n",
    "\n",
    "col_count = 0\n",
    "\n",
    "print(len(weights_exp))\n",
    "#Applies weight to each column\n",
    "for col in df_clean.columns:\n",
    "    df_clean[col] = df_clean[col].mul(weights_exp[col_count])\n",
    "    col_count += 1\n",
    "\n",
    "\n",
    "#Calculates the euclidean (L2) norm of each row and divides the data in each row by the euclidean norm\n",
    "#Saves time when performing Cosine Similarity in main algorithm implementations\n",
    "eucl_norm = np.linalg.norm(df_clean, axis=1)\n",
    "normalized_df = df_clean.div(eucl_norm, axis=0)\n",
    "\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8534eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Makes the AppID a main column again and converts the dataframe to 2D numpy array\n",
    "normalized_df = normalized_df.reset_index()\n",
    "normalized_df.drop(columns=[\"AppID\"], inplace=True)\n",
    "numpy_matrix = normalized_df.to_numpy()\n",
    "\n",
    "#Creates output paths for 2d numpy array and metadata files\n",
    "dir = \"resources\"\n",
    "subfolder = \"preprocessed_data\"\n",
    "sub_path = os.path.join(dir, subfolder)\n",
    "numpy_path = os.path.join(sub_path, \"preprocessed_data_matrix.npy\")\n",
    "metadata_path = os.path.join(sub_path, \"game_metadata.json\")\n",
    "\n",
    "#Writes the 2d numpy array to a npy file\n",
    "np.save(numpy_path, numpy_matrix)\n",
    "\n",
    "#Converts dataframe containing metadata to a dictionary, with AppID as the key\n",
    "game_metadata_dict = df_metadata.to_dict('index')\n",
    "\n",
    "#Writes a list of column headers for the numpy matrix and metadata dictionary to a JSON file\n",
    "with open(metadata_path, 'w') as file:\n",
    "    '''json.dump(normalized_df.columns.to_list(), file)\n",
    "    file.write('\\n')'''\n",
    "    json.dump(game_metadata_dict, file, indent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing/easy visualization of processed data\n",
    "#normalized_df = pd.concat([df_metadata[[\"Name\"]], normalized_df], axis=1)\n",
    "#normalized_df.to_csv(\"preprocessed_data.csv\", index=False)\n",
    "\n",
    "numpy_matrix_test = np.load(numpy_path)\n",
    "print(numpy_matrix_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
